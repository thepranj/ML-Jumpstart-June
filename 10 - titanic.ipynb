{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic\n",
    "\n",
    "In this example, we use the Titanic dataset to predict the survival of passengers on the Titanic. You can download the Jupyter Notebook of the study <a href=\"titanic.ipynb\">here</a>.\n",
    "\n",
    "## Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy import *\n",
    "new_auto_connection({\"host\": \"34.237.154.116\", \n",
    "                     \"port\": \"5433\", \n",
    "                     \"database\": \"testdrive\", \n",
    "                     \"password\": \"password\", \n",
    "                     \"user\": \"dbadmin\"},\n",
    "                    name = \"VerticaDSN\")\n",
    "# Set the primary auto-connection\n",
    "change_auto_connection(\"VerticaDSN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following command to allow Matplotlib to display graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy.datasets import load_titanic\n",
    "from verticapy import *\n",
    "titanic = load_titanic()\n",
    "display(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = vDataFrame('titanic')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Preparation\n",
    "\n",
    "Let's explore the data by displaying descriptive statistics of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(method = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns \"body\" (passenger ID), \"home.dest\" (passenger origin/destination), \"embarked\" (origin port) and \"ticket\" (ticket ID) shouldn't influence survival, so we can ignore these.\n",
    "\n",
    "Let's focus our analysis on the columns \"name\" and \"cabin.\" We'll begin with the passgeners' names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext verticapy.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from models;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy.learn.preprocessing import CountVectorizer\n",
    "model = CountVectorizer(\"name_voc4\")\n",
    "model.drop()\n",
    "model.fit(titanic, [\"Name\"]).transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext verticapy.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    REGEXP_SUBSTR(name, '([A-Za-z]+\\.)') as TITLE,\n",
    "    count(*),\n",
    "    AVG(survived)\n",
    "FROM titanic GROUP BY 1 order by 3 desc;    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract each passenger's title through their name, which might come in handy.\n",
    "\n",
    "Let's move on to the cabins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy.learn.preprocessing import CountVectorizer\n",
    "model = CountVectorizer(\"cabin_voc9\")\n",
    "model.drop()\n",
    "model.fit(\"titanic\", [\"cabin\"]).transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have the cabin IDs, the letter of which represents a certain position on the boat. Let's look at the number of occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer(\"cabin_voc10\").fit(\"titanic\", [\"cabin\"]).transform(\n",
    "                )[\"token\"].str_slice(1, 1).groupby(\n",
    "                columns = [\"token\"], expr = [\"SUM(cnt)\"]).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULL values for \"cabin\" might represent passengers without a cabin. If this is the case, then these are missing values not at random (MNAR).\n",
    "\n",
    "NULL values for \"boat\" represent passengers who have a dedicated \"lifeboat.\" We can drop the useless columns and encode the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop([\"body\", \"home.dest\", \"embarked\", \"ticket\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"cabin\"].str_slice(1, 1)[\"name\"].str_extract(\n",
    "        ' ([A-Za-z]+)\\.')[\"boat\"].fillna(\n",
    "        method = \"0ifnull\")[\"cabin\"].fillna(\"No Cabin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our assumption about the meaning of a NULL value of \"cabin\" turned out to be incorrect; after all, first class passengers should have a cabin. This means that the \"cabin\" column has far too many missing values at random (MAR). We'll have to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"cabin\"].drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at descriptive statistics of the entire Virtual Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(method = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will help us better understand our data. Let's draw histogram for \"age\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"age\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform a Jarque-Bera test to test our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy.stats import jarque_bera\n",
    "# Does this follow a normal distribution?\n",
    "jarque_bera(titanic, \"age\", alpha = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice also that the column \"fare\" has many outliers (The maximum of 512.33 is much greater than the 9th decile of 79.13). Most of the passengers traveled in 3rd class (median of pclass = 3) and much more...\n",
    "\n",
    "The \"sibsp\" column represents the number of siblings, while the \"parch\" column represents the number of parents and children. We can use these to create a new feature: \"family_size\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"family_size\"] = titanic[\"parch\"] + titanic[\"sibsp\"] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deal with the outliers. We have several options to find them (LocalOutlier Factor, DBSCAN, k-means...) but we will just use winsorization. Our target is the \"fare\" distribution since it has so many outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit extreme values, all data above 97th percentile, is set to 97th percentile\n",
    "titanic[\"fare\"].fill_outliers(method = \"winsorize\", \n",
    "                              alpha = 0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode the column \"sex\" so we can use it with numerical methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"sex\"].label_encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.current_relation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column \"age\" has too many missing values and since most machine learning algorithms don't handle missing values, we need to use imputation techniques. Let's fill the missing values using the average \"age\" of the passengers that have the same \"pclass\" and \"sex.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"age\"].fillna(method = \"mean\", by = [\"pclass\", \"sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw the correlation matrix to see the links between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.corr(method = \"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare correlates strongly with family size. This is about what you would expect: it makes sense that the larger the family, the more tickets they'd have to buy, and the greater the fare.\n",
    "\n",
    "Survival correlates strongly with whether or not a passenger has a lifeboat (the \"boat\" variable). Still, to increase the generality of our model, we should avoid predictions based on just one variable. Let's split the study into two use cases:\n",
    "\n",
    "<ul>\n",
    "    <li>Passengers with a lifeboat</li>\n",
    "    <li>Passengers without a lifeboat</li>\n",
    "</ul>\n",
    "\n",
    "Before we move on: we did a lot of work to clean up this data, but we haven't saved anything to our Vertica database! We can look at our vDataFrame to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.current_relation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see what's happening when we aggregate and turn on SQL generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_option(\"sql_on\", True)\n",
    "titanic.avg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VerticaPy dynamically generates SQL code whenever you make modifications to your data. It will also store computed aggregations to avoid unnecessary recomputation. If we filter anything, it will update the catalog with our modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option(\"sql_on\", False)\n",
    "print(titanic.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to data modeling. Save the vDataframe in your Vertica database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy import drop_view\n",
    "drop_view(\"titanic_boat\")\n",
    "drop_view(\"titanic_no_boat\")\n",
    "\n",
    "titanic_boat = titanic.search(conditions = [\"boat = 1\"])\n",
    "titanic_no_boat = titanic.search(conditions = [\"boat = 0\"])\n",
    "#titanic.to_dbtitanic.filter(titanic[\"boat\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_boat.to_db(name = '\"public\".\"titanic_boat\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_no_boat.to_db(name = '\"public\".\"titanic_no_boat\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "### Passengers with a lifeboat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the number of survivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy import vDataFrame\n",
    "titanic_boat = vDataFrame(\"titanic_boat\")\n",
    "titanic_boat[\"survived\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 9 deaths. Let's try to understand why these passengers died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_boat.filter(titanic_boat[\"survived\"] == 0).head(10)\n",
    "titanic_boat.search(conditions = [\"survived = 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from third-class passengers, it doesn't seem like these passengers have any predictors for their deaths. Making a model out of this would be unhelpful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passengers without a lifeboat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to passengers without a lifeboat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_boat = vDataFrame(\"titanic_no_boat\")\n",
    "titanic_boat[\"survived\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 20 survived. Let's find out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_boat.filter(titanic_boat[\"survived\"] == 1).head(20)\n",
    "titanic_boat.search(conditions = [\"survived = 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most survivors seem to be women. Let's build a model with this.\n",
    "\n",
    "One of our predictors is categorical: the passenger title. Some of these predictors are corrleated, so it'd be best to work with a non-linear classifier that can handle that. In this case, random forest seems to be perfect. Let's evaluate it with a cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verticapy.learn.ensemble import RandomForestClassifier\n",
    "from verticapy.learn.model_selection import cross_validate\n",
    "\n",
    "predictors = titanic.get_columns(exclude_columns = ['\"survived\"'])\n",
    "response = \"survived\"\n",
    "relation = \"titanic_no_boat\"\n",
    "model = RandomForestClassifier(\"rf_titanic\", \n",
    "                               n_estimators = 40, \n",
    "                               max_depth = 4)\n",
    "cross_validate(model, relation, predictors, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is pretty unbalanced so we'll use AUC to evaluate it.\n",
    "\n",
    "The model is very good with an average greater than 0.9!\n",
    "\n",
    "We can now build a model with the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(relation, predictors, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the features importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, a passenger's title and the sex are the most important predictors of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've solved our problem in a Pandas-like way, all without ever loading data into memory!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
